{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <center>ANÁLISIS DE REGRESIÓN \n",
    "## Proyecto Final de Semestre (Código de Ejecucción)\n",
    "###  Berriel Rangel Abraham  (315079885)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo del trabajo es constuir un modelo de Regresión Lineal para predecir la cantidad de tarifa esperada por viajes de un conjunto de datos el cual contiene los registros de los viajes realizados en el año 2018.\n",
    "\n",
    "Los datos utilizados en el presente trabajo fueron recopilados y proporcionados a la Comisión de taxis y limusinas de la ciudad de Nueva York \"Taxi and Limousine Commission(TLC)\" por proveedores de tecnología autorizados en virtud de los Programas de mejora de pasajeros de taxis \"Taxicab & Livery Passenger Enhancement Programs\" (TPEP / LPEP). \n",
    "\n",
    "Primeramente importaremos una muestra representatriva de la base de datos, sobre la cual se realizara su respectuva limpieza, análisis exploratorio e ingeniería de datos para obtener una predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T00:18:52.317069Z",
     "start_time": "2020-12-27T00:18:52.303968Z"
    }
   },
   "source": [
    "# 1. Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-23T16:41:53.009Z"
    }
   },
   "outputs": [],
   "source": [
    "#pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:42:04.236356Z",
     "start_time": "2021-01-23T16:42:02.367440Z"
    }
   },
   "outputs": [],
   "source": [
    "#librerias\n",
    "\n",
    "# Tratamiento de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Preprocesado y modelado\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T23:25:52.976210Z",
     "start_time": "2021-01-23T23:25:52.944664Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd  # para los dataframes \n",
    "import pickle  #I/O of BLOBs\n",
    "import scipy.stats as stat  # para los test estadisticos\n",
    "from scipy.stats import pearsonr  #para los coeficiientes de correlación\n",
    "from datetime import datetime  #timestamps\n",
    "from collections import Counter  #para index\n",
    "import itertools as it  #combinations and something else\n",
    "import numpy as np  #python para trabajar con arreglos.\n",
    "import matplotlib.pyplot as plt  #plots\n",
    "import seaborn as sns  #otra libreria para plotear, pero más chida\n",
    "import folium  # libreria para crear mapas \n",
    "import json  # leer los .json que necesitemos\n",
    "import matplotlib  #\n",
    "import warnings\n",
    "import statsmodels as sm\n",
    "matplotlib.style.use('ggplot')  #nice plots\n",
    "from pandas.plotting import table\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Importar datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que tenemos una enorme cantidad de datos (112 M) y nuestros recursos de software son limitados nos concentraremos en obtener una muestra representativa de los datos para tratar la información, dicha muestra es una muestra aleatoria estratificada, es decir, la muestra se realizara de acuerdo a una o mas variables categoricas definidas, las cuales estarán en las mismas proporciones respecto a la población total, los 112 millones de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para eso crearemos una fución que nos permita obtener una muestra estratificada, dicha función realiza su tarea leyendo el archivo por \"chunks\" y sacando una muestra estratificada para cada chunk, muestras que en conjunto serán los datos que utilizaremos para nuestro trabajo, también definimos una función para obtener la proporción de datos de cada estrato respecto a la población para verificar que tomamos una muestra proporcional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:42:07.550213Z",
     "start_time": "2021-01-23T16:42:07.534209Z"
    }
   },
   "outputs": [],
   "source": [
    "def muestreo_estratificado(file,N,variables, cs = None):\n",
    "    muestra = pd.DataFrame([])\n",
    "    for df in pd.read_csv(file, chunksize=cs):\n",
    "        N = N\n",
    "        m1=df.groupby(variables,group_keys=False).apply(lambda x: x.sample(int(np.rint(N*len(x)/len(df))))).sample(frac=1).reset_index(drop=True)\n",
    "        muestra = muestra.append(m1)\n",
    "    return muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:42:08.282657Z",
     "start_time": "2021-01-23T16:42:08.274624Z"
    }
   },
   "outputs": [],
   "source": [
    "def proporciones(file, variables, cs = None):\n",
    "    P = pd.DataFrame([])\n",
    "    s=0\n",
    "    for df in pd.read_csv(file, chunksize=cs):\n",
    "        s = s + df.shape[0]\n",
    "        P = P.append(df.groupby(variables)['VendorID'].count()) \n",
    "    P[\"col\"]= \"total\"\n",
    "    Proporciones = P.groupby('col').sum().T\n",
    "    Proporciones[\"prop\"] = Proporciones[\"total\"]/s\n",
    "    return Proporciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que nuestro objetivo no solo es tener información, si no que esa información sea signifcante, debemos tener una proporción equitativa de datos respecto a una variable de interés,para efectos de número de datos, tomaremos los ID de empresas de taxis, para que todo el sistema de los mismos este bien representado, mientras que si se quisiera una proporción representativa respecto a otra variable sería analogo a lo mostrado abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:20:54.597042Z",
     "start_time": "2021-01-23T16:17:44.233130Z"
    }
   },
   "outputs": [],
   "source": [
    "prop = proporciones('C:/Users/berri/Desktop/Arcade/nyc_taxi/2018_Yellow_Taxi_Trip_Data.csv','VendorID',cs=3000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:21:35.836066Z",
     "start_time": "2021-01-23T16:21:35.820047Z"
    }
   },
   "outputs": [],
   "source": [
    "prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:21:39.840219Z",
     "start_time": "2021-01-23T16:21:39.816197Z"
    }
   },
   "outputs": [],
   "source": [
    "prop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí nos indican que habría que tomar 41.9% de la empresa 1, 57.6618% de la empresa 2 y 4.381% de la empresa 4 (sin embargo sabemos que solo existen 2 empresas de taxis de NY, por lo cual es un indicio que hay inconsistencias que habrá que arreglar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T00:20:59.885850Z",
     "start_time": "2020-12-27T00:20:59.867939Z"
    }
   },
   "source": [
    "## 2.1.- Reconocimiento de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:30:58.091474Z",
     "start_time": "2021-01-23T16:27:40.067812Z"
    }
   },
   "outputs": [],
   "source": [
    "df = muestreo_estratificado('C:/Users/berri/Desktop/Arcade/nyc_taxi/2018_Yellow_Taxi_Trip_Data.csv',10000, \"VendorID\", 3000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:42:19.181719Z",
     "start_time": "2021-01-23T16:42:15.786259Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:/Users/berri/Desktop/chido.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:42:21.911621Z",
     "start_time": "2021-01-23T16:42:21.879641Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T00:49:45.006539Z",
     "start_time": "2021-01-15T00:49:44.990956Z"
    }
   },
   "source": [
    "Veamos que nuestros datos se componen de 17 columnas las cuales las podemos diferenciar de dos tipos distintos, variables categoricas y variables cuantitativas, entre estas se encuentran:\n",
    "#### - variables categoricas: \n",
    "        * VendorID\n",
    "        * RatecodeID\n",
    "        * store_and_fwd_flag\n",
    "        * PULocationID\n",
    "        * DOLocationID\n",
    "        * payment_type\n",
    "#### - variables cuantitativas: \n",
    "        * tpep_pickup_datetime \t\n",
    "        * tpep_dropoff_datetime \n",
    "        * passenger_count \t\n",
    "        * trip_distance\n",
    "        * PULocationID \t\n",
    "        * DOLocationID \t\n",
    "        * payment_type \t\n",
    "        * fare_amount \t\n",
    "        * extra \t\n",
    "        * mta_tax \t\n",
    "        * tip_amount \t\n",
    "        * tolls_amount \t\n",
    "        * improvement_surcharge \t\n",
    "        * total_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T00:51:52.052929Z",
     "start_time": "2021-01-15T00:51:52.015105Z"
    }
   },
   "source": [
    "Podemos ver que las variables categoricas nos muestran las columnas que que se relacionaran los catalogos de nuestro modelo relacional, ademas las variables cuantitativas, tpep_pickup_datetime, tpep_dropoff_datetime son columnas con fechas, estas requeriran un tratamiento especial, las variables cuantitativas restantes se analizaran buscando anomalias en los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:31:10.987665Z",
     "start_time": "2021-01-23T16:31:10.751321Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abajo podemos observar que esta muestra que tenemos es representativa respecto a las proporciones que antes nos fueron dadas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:42:28.681398Z",
     "start_time": "2021-01-23T16:42:28.657417Z"
    }
   },
   "outputs": [],
   "source": [
    "df.VendorID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:42:31.405468Z",
     "start_time": "2021-01-23T16:42:31.373459Z"
    }
   },
   "outputs": [],
   "source": [
    "df['VendorID'].value_counts() / len(df['VendorID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.- Tratamiento de datos crudos, anomalías y outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 .- Conversión a datatime de datos y creación de \"duración de viaje\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:42:57.457320Z",
     "start_time": "2021-01-23T16:42:52.166967Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"tpep_pickup_datetime\"] = pd.to_datetime(df[\"tpep_pickup_datetime\"], format= '%m/%d/%Y %I:%M:%S %p' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:43:04.648864Z",
     "start_time": "2021-01-23T16:42:59.304028Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"tpep_dropoff_datetime\"] = pd.to_datetime(df[\"tpep_dropoff_datetime\"], format= '%m/%d/%Y %I:%M:%S %p' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:43:06.667965Z",
     "start_time": "2021-01-23T16:43:06.540019Z"
    }
   },
   "outputs": [],
   "source": [
    "(df['tpep_dropoff_datetime'].dt.month).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:43:07.925989Z",
     "start_time": "2021-01-23T16:43:07.790158Z"
    }
   },
   "outputs": [],
   "source": [
    "(df['tpep_dropoff_datetime'].dt.year).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:43:09.640481Z",
     "start_time": "2021-01-23T16:43:09.349176Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Anterior tamaño: %d' % len(df))\n",
    "df = df[df[\"tpep_dropoff_datetime\"].dt.year==2018]\n",
    "print('Nuevo tamaño: %d' % len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que respecto a los meses, nuestro catálogo de datos tambien está bien distribuido respecto al número de meses que toma, a la par que creamos una nueva columna bastante importante\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:43:11.587034Z",
     "start_time": "2021-01-23T16:43:11.419146Z"
    }
   },
   "outputs": [],
   "source": [
    "df['trip_duration_min'] = round(((df['tpep_dropoff_datetime']-df['tpep_pickup_datetime']).dt.seconds)/60, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:43:12.138481Z",
     "start_time": "2021-01-23T16:43:12.130485Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"trip_duration_min\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 .- Tratamiento de anomalías respecto a VendorID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:43:32.832037Z",
     "start_time": "2021-01-23T16:43:13.463543Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.catplot(x=\"VendorID\", y=\"trip_duration_min\",kind=\"strip\",data=df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el gráfico de arriba podemos notar inmediatamente dos valores que hay que erradicar:\n",
    "#### - Viajes con duración de hasta 1200 min \n",
    "#### - Existencia de una cuarta empresa de Taxi NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:43:36.622198Z",
     "start_time": "2021-01-23T16:43:36.352060Z"
    }
   },
   "outputs": [],
   "source": [
    "df['VendorID'].hist(bins=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que si bien no es de gran número respecto a las otras dos empresas , lo mejor es eliminarlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:43:38.742348Z",
     "start_time": "2021-01-23T16:43:38.582116Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Anterior tamaño: %d' % len(df))\n",
    "df = df[df.VendorID<4]\n",
    "print('Nuevo tamaño: %d' % len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 .- Distacia de viaje iguales a cero y tiempo de viaje "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:43:40.512007Z",
     "start_time": "2021-01-23T16:43:40.232208Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(df['trip_duration_min'],kde=False)\n",
    "plt.title('Distribution Duration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:43:42.093959Z",
     "start_time": "2021-01-23T16:43:41.840572Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(df['trip_distance'],kde=False)\n",
    "plt.title('Distribution Duration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto deja en claro que en muchas ocasiones los histogramas están muy lejos de proveer una buena información acerca de los outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:43:43.937641Z",
     "start_time": "2021-01-23T16:43:43.793708Z"
    }
   },
   "outputs": [],
   "source": [
    "dist_0 = df[df[\"trip_distance\"]==0]\n",
    "my_plot = dist_0.plot(\"trip_distance\", \"passenger_count\", kind=\"scatter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:43:45.311998Z",
     "start_time": "2021-01-23T16:43:45.106232Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Anterior tamaño: %d' % len(df))\n",
    "df = df[df.trip_distance>0]\n",
    "print('Nuevo tamaño: %d' % len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T01:31:54.789680Z",
     "start_time": "2021-01-15T01:31:54.774096Z"
    }
   },
   "source": [
    "Verificamos que realmente hayan desaparecido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:43:47.253324Z",
     "start_time": "2021-01-23T16:43:47.133361Z"
    }
   },
   "outputs": [],
   "source": [
    "dist_0 = df[df[\"trip_distance\"]==0]\n",
    "my_plot = dist_0.plot(\"trip_distance\", \"passenger_count\", kind=\"scatter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:43:48.881052Z",
     "start_time": "2021-01-23T16:43:48.873056Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"trip_duration_min\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:44:04.435580Z",
     "start_time": "2021-01-23T16:43:50.394460Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot histogram of fare\n",
    "df[df.trip_duration_min<1439.9].trip_duration_min.hist(bins=10000, figsize=(14,3))\n",
    "plt.xlabel('Duration in minutes')\n",
    "plt.title('Histogram');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:44:09.620883Z",
     "start_time": "2021-01-23T16:44:09.612887Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"trip_duration_min\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos presencia muy importante de outliers para la parte de la duración de viajes. Por lo que consideramos que a partir de 3 horas podemos consideras que los viajes son anomalías dado que incluso con outliers la media es 30 min por viaje. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:44:11.131715Z",
     "start_time": "2021-01-23T16:44:10.931814Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Tamaño anterior: %d' % len(df))\n",
    "df = df[df.trip_duration_min<180]\n",
    "print('Nuevo tamaño: %d' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:44:12.549866Z",
     "start_time": "2021-01-23T16:44:12.525881Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"trip_duration_min\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:44:27.593763Z",
     "start_time": "2021-01-23T16:44:14.082408Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot histogram of fare\n",
    "df[df.trip_duration_min<1798].trip_duration_min.hist(bins=10000, figsize=(14,3))\n",
    "plt.xlabel('Duración en minutos')\n",
    "plt.title('Histograma');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Numero de pasajeros igual a cero y mayores a 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente para esta parte nos dimos cuenta que existian registros en los cuales existen viajes con cero pasajeros regitrados, dado que esto es una inconsistencia decididos eliminar dichos registros, ademas, la normatividad que regula estos taxis indica que la cantidad máxima de pasajeros permitidos en un taxi amarillo por ley es de cuatro, en un taxi de cuatro pasajeros o de cinco pasajeros en un taxi de cinco pasajeros, excepto que se debe aceptar un pasajero adicional si tal El pasajero es menor de siete años y está sostenido en el regazo de un pasajero adulto sentado en la parte trasera. Por dicha razón se decidio eliminar lor registros con pasajeros cero y mayores a 6.\n",
    "\n",
    "La informacion mencionada en el parrafo anterior se puede verificar en la pagina 33 de la siguente fuente:\n",
    "\n",
    "https://www1.nyc.gov/assets/tlc/downloads/pdf/rule_book_current_chapter_54.pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:44:31.747352Z",
     "start_time": "2021-01-23T16:44:31.358728Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(df['passenger_count'], orient='horizontal')\n",
    "plt.title('Box Plot de los pasajeros')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:44:36.545569Z",
     "start_time": "2021-01-23T16:44:36.129912Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(df['total_amount'], orient='horizontal')\n",
    "plt.title('Box Plot de las tarifas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:44:38.411567Z",
     "start_time": "2021-01-23T16:44:38.228434Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Tamaño anterior: %d' % len(df))\n",
    "df = df[df.total_amount<200]\n",
    "print('Nuevo tamaño: %d' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:44:39.404263Z",
     "start_time": "2021-01-23T16:44:39.152625Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(df['total_amount'],kde=False)\n",
    "plt.title('Disribución del Pago')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:44:42.251076Z",
     "start_time": "2021-01-23T16:44:42.059203Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Tamaño anterior: %d' % len(df))\n",
    "df = df[df.total_amount>0]\n",
    "print('Nuevo tamaño: %d' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:44:43.902808Z",
     "start_time": "2021-01-23T16:44:43.495528Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(df['total_amount'], orient='horizontal')\n",
    "plt.title('Box Plot de las tarifas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:44:48.562051Z",
     "start_time": "2021-01-23T16:44:48.401824Z"
    }
   },
   "outputs": [],
   "source": [
    "pasajeros_0 = df[df[\"passenger_count\"]<=0]\n",
    "my_plot = pasajeros_0.plot(\"passenger_count\", \"total_amount\", kind=\"scatter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:44:54.105102Z",
     "start_time": "2021-01-23T16:44:53.985179Z"
    }
   },
   "outputs": [],
   "source": [
    "pasajeros_0 = df[df[\"passenger_count\"] > 6]\n",
    "my_plot = pasajeros_0.plot(\"passenger_count\", \"total_amount\", kind=\"scatter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:44:55.497136Z",
     "start_time": "2021-01-23T16:44:55.302054Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Tamaño anterior: %d' % len(df))\n",
    "df = df[df.passenger_count>0]\n",
    "print('Nuevo tamaño: %d' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:44:55.981526Z",
     "start_time": "2021-01-23T16:44:55.790204Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Tamaño anterior: %d' % len(df))\n",
    "df = df[df.passenger_count<=6]\n",
    "print('Nuevo tamaño: %d' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:44:56.633230Z",
     "start_time": "2021-01-23T16:44:56.612699Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"passenger_count\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:44:58.560173Z",
     "start_time": "2021-01-23T16:44:58.552178Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"passenger_count\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.4 Montos totales iguales a cero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este paso nos dimos cuenta que existian viajes con monto total igual a cero pero con numero de pasajeros y distancia registrados, debido a que eso representa una inconsistencia procedemos a eliminar dichas filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:00.349428Z",
     "start_time": "2021-01-23T16:45:00.229472Z"
    }
   },
   "outputs": [],
   "source": [
    "monto_0 = df[df[\"total_amount\"]==0]\n",
    "my_plot = monto_0.plot(\"total_amount\", \"trip_distance\", kind=\"scatter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:01.893081Z",
     "start_time": "2021-01-23T16:45:01.705688Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Tamaño anterior: %d' % len(df))\n",
    "df = df[df.total_amount>0]\n",
    "print('Nuevo tamaño: %d' % len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Verificar que no existan datos blancos o vacíos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:04.271271Z",
     "start_time": "2021-01-23T16:45:03.655545Z"
    }
   },
   "outputs": [],
   "source": [
    "df.isna().sum().plot(kind=\"bar\")\n",
    "data = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:05.577558Z",
     "start_time": "2021-01-23T16:45:05.545552Z"
    }
   },
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:05.969302Z",
     "start_time": "2021-01-23T16:45:05.953317Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ###### - VendorID:\n",
    "        * El valor maximo de esta columna es 4, es decir que existen valores inconsistentes con respecto al\n",
    "        catalogo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T00:54:20.657514Z",
     "start_time": "2020-12-27T00:54:20.643078Z"
    }
   },
   "source": [
    "De acuerdo al grafico anterior correpondiente a VendorID, de su frecuencia y distribución podemos ver que los registros en los cuales su VendorID es 4 representan una proporcion casi nula de los datos, ademas respecto a las columnas de total_amount y PULocationID, los registros con dato VendorID igual a 4, representan proporciones insignificantes comparadas con los datos de VendorID diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - passenger_count:\n",
    "        * Esta columna es cuantitativa pero por su rango tan pequeño lo consideraremos en esta sección para \n",
    "        nuestro analisis\n",
    "        * El valor minimo de esta columna es 0, es decir, existen viajes realizados pero que no registraron \n",
    "        ningun pasajero.\n",
    "        * Deacuerdo a la fuente de informacion debemos considerar pautas establecias para el tratamiento de \n",
    "        esta columna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    Variables cuantitativas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora analizaremos la frecuencia y distribucion de las variables cuantitativas para visualizar las columnas y observaciones a tratar en la  limpieza de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Analizando la tabla y las graficas anteriores llegamos a las siguientes observaciones respecto a estas columnas:\n",
    "   \n",
    "   ###### - total_amount:\n",
    "        * Esta columna es el resultado de la suma de las columnas de fare_amount, extra, mta_tax, tip_amount,\n",
    "        tolls_amount, improvement_surcharge.\n",
    "        * El valor minimo es negativo, por lo que podemos pensar que existen valores negativos en las celdas que\n",
    "        conforman el resultado de total_amount.\n",
    "   ###### - trip_distance:\n",
    "        * El valor minimo de la distancia del viaje es cero, es decir, existen viajes cobrados pero que en la \n",
    "        base de datos no recorrieron distancia alguna.\n",
    "   ###### - extra:\n",
    "        * El mayor volumen de estos registros se encuentran en los valores 0, 0.50. 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ###### - total_amount:\n",
    "        * Esta columna es el resultado de la suma de las columnas de fare_amount, extra, mta_tax, tip_amount,\n",
    "        tolls_amount, improvement_surcharge.\n",
    "        * El valor minimo es negativo, por lo que podemos pensar que existen valores negativos en las celdas que\n",
    "        conforman el resultado de total_amount.\n",
    "   ###### - trip_distance:\n",
    "        * El valor minimo de la distancia del viaje es cero, es decir, existen viajes cobrados pero que en la \n",
    "        base de datos no recorrieron distancia alguna.\n",
    "   ###### - RatecodeID:\n",
    "        * El valor maximo de esta columna es 99, es decir que existen valores inconsistentes con respecto al\n",
    "        catalogo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:11.403655Z",
     "start_time": "2021-01-23T16:45:11.371664Z"
    }
   },
   "outputs": [],
   "source": [
    "(df['passenger_count']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:15.834876Z",
     "start_time": "2021-01-23T16:45:15.818862Z"
    }
   },
   "outputs": [],
   "source": [
    "#Crer catalgos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:16.870880Z",
     "start_time": "2021-01-23T16:45:16.672666Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Old size: %d' % len(df))\n",
    "df = df[df.trip_distance<150]\n",
    "print('New size: %d' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:18.586222Z",
     "start_time": "2021-01-23T16:45:18.570201Z"
    }
   },
   "outputs": [],
   "source": [
    "df.trip_distance.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 .-Carga de código de distritos para mejor análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:20.004132Z",
     "start_time": "2021-01-23T16:45:19.988113Z"
    }
   },
   "outputs": [],
   "source": [
    "zone_lookup = pd.read_csv(\"/Users/berri/Desktop/Arcade/taxi_zone_lookup.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sincronizar columnas con el cargo anterior de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:20.983851Z",
     "start_time": "2021-01-23T16:45:20.972821Z"
    }
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'PULocationID':'LocationID'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.-Análisis Exploratorio Estádistico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de plantear un modelo de regresión creemos oportuno no dejar pasar la oportunidad de hacer un completo análisis de demás rubros que podrían ser de igual intereses que una regresión del total amount para una empresa de Taxis para poder hacer ciertas tomas de decisiones con base en lo expuesto en está parte del escrito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 .- ¿En qué época del año se utilizan más los taxis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "¿En qué época del año se utilizan más los taxis? Creemos una gráfica que, para cada mes, muestre el número promedio de viajes registrados cada día. Debido a las diferencias entre las zonas de Nueva York, queremos visualizar la misma información para cada distrito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos interesados en las recolecciones en lugar de la entrega, por lo que usamos solo la columna 'tpep_pickup_datetime' para nuestro análisis y 'PULocationID' para unir el conjunto de datos con un mapeo entre las identificaciones y el municipio asociado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Las columnas iniciales son:\n",
    "\n",
    "tpep_pickup_datetime Contiene la marca de tiempo exacta en el formato estándar% Y-% m-% d% H:% M:% S.\n",
    "\n",
    "PULocationID Es una identificación única de la ubicación, que se utilizará para unirse al marco de datos que contiene los distritos.\n",
    "\n",
    "El marco de datos resultante está compuesto por dos columnas: una contiene la marca de tiempo de la recolección y la otra contiene el municipio en el que se realiza la recolección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:25.595021Z",
     "start_time": "2021-01-23T16:45:25.365771Z"
    }
   },
   "outputs": [],
   "source": [
    " df1 = df[['tpep_pickup_datetime', 'LocationID']]\n",
    "df1 = df1.merge(zone_lookup[['LocationID', 'Borough']], how='inner' ,on='LocationID') #Inner join entre las columnas de interes\n",
    "df1 = df1[['tpep_pickup_datetime', 'Borough']]\n",
    "#df1 = df1.loc[df['tpep_pickup_datetime'].dt.year == 2018].fillna(0)\n",
    "#display(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:26.919098Z",
     "start_time": "2021-01-23T16:45:26.903106Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos si nuestra muestra contiene datos suficientes de todos los meses del año para poder realizar el análisis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:29.057841Z",
     "start_time": "2021-01-23T16:45:28.921932Z"
    }
   },
   "outputs": [],
   "source": [
    "(df1['tpep_pickup_datetime'].dt.month).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Después del fragmento, tenemos los datos limpios, ¡así que podemos ejecutar nuestras operaciones en eso!\n",
    "\n",
    "## 4.1.1- Ingeniería de datos:\n",
    "Para cada operación que hemos realizado aquí hay una ampliación de por qué realizamos esa operación.\n",
    "\n",
    "## 4.1.2.-Bucle anidado: \n",
    "Para cada distrito y para cada mes, tenemos que dividir el número de recogidas para los días del mes para obtener el promedio diario, por lo que con \"set (df ['Borough'])\" tenemos todos los distritos y con \"for i in range (1, max (df ['pickup']. dt.month) +1)\" iteramos con todos los meses.\n",
    "\n",
    "Para evitar errores construimos una lista de los días del mes en los que el elemento en la posición 0 corresponde a Janaury, el elemento en la posición 1 corresponde a Febraury y así sucesivamente.\n",
    "\n",
    "tmp y tmpdf: En el bucle for anidado hay un marco de datos temporal que almacena las capturas en el mes que estamos analizando, podemos evitarlo, pero en este momento preferimos la legibilidad en lugar de las actuaciones, liberaremos la memoria cada uno y cada vez que pasa el bucle.\n",
    "\n",
    "Usamos vectorización porque pandas está optimizado para operaciones vectoriales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:30.926183Z",
     "start_time": "2021-01-23T16:45:30.670028Z"
    }
   },
   "outputs": [],
   "source": [
    "max(df1['tpep_pickup_datetime'].dt.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:46.211374Z",
     "start_time": "2021-01-23T16:45:32.027406Z"
    }
   },
   "outputs": [],
   "source": [
    "df12 = pd.DataFrame()\n",
    "tmp = pd.Series()\n",
    "months = [31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "for borough in set(df1['Borough']): #\n",
    "    for i in range(1, max(df1['tpep_pickup_datetime'].dt.month)):\n",
    "        tmpdf = df1.loc[(df1['tpep_pickup_datetime'].dt.month == i) & (df1['Borough'] == borough)]['tpep_pickup_datetime']\n",
    "        if len(tmpdf) != 0:\n",
    "            tmp = tmp.append(pd.Series(tmpdf.count()/months[i-1]), ignore_index=True)\n",
    "    df12[borough] = tmp\n",
    "    del tmp\n",
    "    del tmpdf\n",
    "    tmp = pd.Series()\n",
    "df12.rename(index ={0:'Enero', 1:'Febr', 2:'Mar', 3:'Abr', 4:'May', 5:'Jun', 6:'Jul', 7:'Ago',8:'Sept', 9:'Oct', 10:'Nov',11:'Dic'}, inplace = True)\n",
    "df12 = df12.fillna(0)\n",
    "display(df12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:50.758459Z",
     "start_time": "2021-01-23T16:45:50.742435Z"
    }
   },
   "outputs": [],
   "source": [
    "df12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.3.- Gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:54.492720Z",
     "start_time": "2021-01-23T16:45:53.510674Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df12.plot.bar(figsize=(20,20),subplots=True,layout=(5,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.4.- Obtención de datos diarios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:45:57.862925Z",
     "start_time": "2021-01-23T16:45:56.963515Z"
    }
   },
   "outputs": [],
   "source": [
    "df['pickup_day']=df['tpep_pickup_datetime'].dt.day_name()\n",
    "df['dropoff_day']=df['tpep_dropoff_datetime'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:46:02.592544Z",
     "start_time": "2021-01-23T16:45:59.999106Z"
    }
   },
   "outputs": [],
   "source": [
    "figure,ax=plt.subplots(nrows=2,ncols=1,figsize=(10,10))\n",
    "sns.countplot(x='pickup_day',data=df,ax=ax[0])\n",
    "ax[0].set_title('Número de viajes solicitados en cada día de la semana')\n",
    "sns.countplot(x='dropoff_day',data=df,ax=ax[1])\n",
    "ax[1].set_title('Número de viajes concluidos en cada día de la semana')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:46:06.568779Z",
     "start_time": "2021-01-23T16:46:06.560751Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:47:07.251212Z",
     "start_time": "2021-01-23T16:46:08.679825Z"
    }
   },
   "outputs": [],
   "source": [
    "def timezone(x):\n",
    "    if x>=datetime.time(4, 0, 1) and x <=datetime.time(10, 0, 0):\n",
    "        return 'Mañana'\n",
    "    elif x>=datetime.time(10, 0, 1) and x <=datetime.time(16, 0, 0):\n",
    "        return 'Medio día'\n",
    "    elif x>=datetime.time(16, 0, 1) and x <=datetime.time(22, 0, 0):\n",
    "        return 'Atardecer'\n",
    "    elif x>=datetime.time(22, 0, 1) or x <=datetime.time(4, 0, 0):\n",
    "        return 'Noche'\n",
    "    \n",
    "df['pickup_timezone']=df['tpep_pickup_datetime'].apply(lambda x :timezone(datetime.datetime.strptime(str(x), '%Y-%m-%d %H:%M:%S').time()) )\n",
    "df['dropoff_timezone']=df['tpep_dropoff_datetime'].apply(lambda x :timezone(datetime.datetime.strptime(str(x), '%Y-%m-%d %H:%M:%S').time()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T21:55:21.044745Z",
     "start_time": "2021-01-23T21:55:19.108605Z"
    }
   },
   "outputs": [],
   "source": [
    "figure,ax=plt.subplots(nrows=2,ncols=1,figsize=(10,10))\n",
    "sns.countplot(x='pickup_timezone',data=df,ax=ax[0], edgecolor=sns.color_palette(\"dark\", 3), linewidth=20)\n",
    "ax[0].set_title('La frecuencia de viajes solicitados en franjas horarias')\n",
    "sns.countplot(x='dropoff_timezone',data=df,ax=ax[1], edgecolor=sns.color_palette(\"dark\", 3), linewidth=20)\n",
    "ax[1].set_title('La frecuencia de viajes terminados en franjas horarias')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:47:45.685749Z",
     "start_time": "2021-01-23T16:47:45.146000Z"
    }
   },
   "outputs": [],
   "source": [
    "figure,ax=plt.subplots(nrows=1,ncols=2,figsize=(10,5))\n",
    "df['pickup_hour']=df['tpep_pickup_datetime'].dt.hour\n",
    "df.pickup_hour.hist(bins=24,ax=ax[0])\n",
    "ax[0].set_title('Distribución de la duración de viajes')\n",
    "df['dropoff_hour']=df['tpep_dropoff_datetime'].dt.hour\n",
    "df.dropoff_hour.hist(bins=24,ax=ax[1])\n",
    "ax[1].set_title('Distribución de las dejadas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:47:48.226480Z",
     "start_time": "2021-01-23T16:47:47.890862Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.title('BoxPlot de la duración de los viajes en minutos')\n",
    "sns.boxplot(df['trip_duration_min'], orient='horizontal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:47:51.415854Z",
     "start_time": "2021-01-23T16:47:51.351869Z"
    }
   },
   "outputs": [],
   "source": [
    "bins=np.array([0,5,15,30,60,150])\n",
    "df['duration_time']=pd.cut(df.trip_duration_min,bins,labels=[\"< 10\", \"11-25\", \"25-40\",\"40-60\",\">60\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:47:54.479475Z",
     "start_time": "2021-01-23T16:47:53.599456Z"
    }
   },
   "outputs": [],
   "source": [
    "ax1=df.groupby('pickup_day')['duration_time'].value_counts(normalize=True).unstack()\n",
    "ax1.plot(kind='bar', stacked='True')\n",
    "plt.title('La distribucion del porcentaje de las diferentes duraciones de los viajes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:47:59.118490Z",
     "start_time": "2021-01-23T16:47:56.577541Z"
    }
   },
   "outputs": [],
   "source": [
    "figure,ax=plt.subplots(nrows=1,ncols=3,figsize=(15,5))\n",
    "ax1=df[(df.duration_time !=\"< 10\")].groupby('pickup_day')['duration_time'].count()\n",
    "ax1.plot(kind='bar',ax=ax[0])\n",
    "ax[0].set_title('Frecuencia de viajes por dia')\n",
    "ax2=df[(df.duration_time !=\"< 10\")].groupby('pickup_day')['duration_time'].value_counts(normalize=True).unstack()\n",
    "ax2.plot(kind='bar', stacked='True',ax=ax[1])\n",
    "ax[1].set_title('Porcentaje de viajes en distintas franjas horarias')\n",
    "ax3=df[(df.duration_time !=\"< 10\")].groupby('pickup_day')['duration_time'].value_counts().unstack()\n",
    "ax3.plot(kind='bar',ax=ax[2])\n",
    "ax[2].set_title('Comparación de horarios')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.5 .- Conclusiones para RQ1\n",
    "Notamos que Manhattan tiene una gran cantidad de viajes promedio diarios, también observamos que la distribución es una especie de uniforme) para la mayoría de los distritos.\n",
    "\n",
    "Si cambiamos la escala del promedio diario (de lo contrario, Manhattan tomará toda la densidad) podemos ver que el mes con más conteos es Janaury.\n",
    "\n",
    "Con una breve charla con una amiga, me dijo que Manhattan tiene esta enorme cantidad de taxis amarillos con respecto a otros distritos porque una ley no permite entrada de taxis verdes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:48:01.348726Z",
     "start_time": "2021-01-23T16:48:01.332708Z"
    }
   },
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.- ¿Cuáles son las franjas horarias con más pasajeros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.1 Planteamiento\n",
    "    ¿Cuáles son las franjas horarias con más pasajeros? Establezca sus propios intervalos de tiempo y descubra cuáles son aquellos en los que los taxis conducen el mayor número de pasajeros en general en Nueva York y repita el análisis para cada distrito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:48:05.620083Z",
     "start_time": "2021-01-23T16:48:05.185959Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df[['LocationID', 'tpep_pickup_datetime', 'passenger_count']]\n",
    "df2 = df2.merge(zone_lookup[['LocationID', 'Borough']], how='inner' ,on='LocationID').fillna(0) # Inner Join entre las columnas interes y nuestro previo csv\n",
    "df2 = df2.drop(['LocationID'], axis=1) #Tirar tablas inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:48:07.146471Z",
     "start_time": "2021-01-23T16:48:07.132662Z"
    }
   },
   "outputs": [],
   "source": [
    "trips = {0:\"1 to 6\", 1:\"1 to 6\", 2:\"1 to 6\", 3:\"1 to 6\", 4: \"1 to 6\", 5: \"1 to 6\", 6: \"1 to 6\", \n",
    "         7:\"7 to 11\", 8:\"7 to 11\", 9:\"7 to 11\", 10:\"7 to 11\", 11:\"7 to 11\", \n",
    "         12:\"12 to 14\", 13:\"12 to 14\", 14: \"12 to 14\", \n",
    "         15:\"15 to 19\", 16:\"15 to 19\", 17: \"15 to 19\", 18:\"15 to 19\", 19:\"15 to 19\",\n",
    "         20:\"20 to 22\", 21: \"20 to 22\", 22: \"20 to 22\", \n",
    "         23:\"23 to 24\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:48:09.017856Z",
     "start_time": "2021-01-23T16:48:08.872341Z"
    }
   },
   "outputs": [],
   "source": [
    "df2['tpep_pickup_datetime'] = df2['tpep_pickup_datetime'].dt.hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:48:10.523769Z",
     "start_time": "2021-01-23T16:48:10.459795Z"
    }
   },
   "outputs": [],
   "source": [
    "df2['tpep_pickup_datetime'] = df2['tpep_pickup_datetime'].map(trips)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:48:11.995138Z",
     "start_time": "2021-01-23T16:48:11.985087Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:48:13.744565Z",
     "start_time": "2021-01-23T16:48:13.470616Z"
    }
   },
   "outputs": [],
   "source": [
    "df22 = df2.groupby(['Borough','tpep_pickup_datetime'])\n",
    "df23 = df22.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:48:16.076796Z",
     "start_time": "2021-01-23T16:48:15.244716Z"
    }
   },
   "outputs": [],
   "source": [
    "df23.groupby('Borough').plot.bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:48:20.718201Z",
     "start_time": "2021-01-23T16:48:20.702197Z"
    }
   },
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Distribuciones de los viajes por distrito \n",
    "    En esta sección nos concentramos en desallorar una ingeniería de datos capaz de poder agrupar por distritos todos los diferentes viajes realizados en ellos y con esa información poder nosotros ajustar una función de distribución para que esa misma información sea de utilidad al tratar de desarollar otro enfoque de ánalisis estadístico sobre el mismo conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:48:22.350278Z",
     "start_time": "2021-01-23T16:48:22.319191Z"
    }
   },
   "outputs": [],
   "source": [
    "df3 = df[['LocationID', 'DOLocationID', 'trip_duration_min']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:48:24.899438Z",
     "start_time": "2021-01-23T16:48:23.831514Z"
    }
   },
   "outputs": [],
   "source": [
    "df3.dropna(inplace=True) \n",
    "df3.rename(columns= {'LocationID':'PULocationID'}, inplace=True)\n",
    "\n",
    "#merge df3 y zone_lookup para el vecindario de donde se tomo el taxi\n",
    "trips = df3.merge(zone_lookup[['LocationID', 'Borough']], how='inner',\n",
    "                      left_on='PULocationID',\n",
    "                      right_on='LocationID').fillna(\"\")[['trip_duration_min','PULocationID','DOLocationID','Borough']]\n",
    "\n",
    "trips.rename(columns= {'Borough':'PUBorough'}, inplace=True)\n",
    "\n",
    "# merrge entre trips y vecindarios para ver donde se bajo el taxi\n",
    "trips = trips.merge(zone_lookup[['LocationID', 'Borough']], how='inner',\n",
    "                      left_on='DOLocationID',\n",
    "                      right_on='LocationID').fillna(\"\")[['trip_duration_min','PULocationID','DOLocationID','PUBorough','Borough']]\n",
    "\n",
    "trips.rename(columns= {'Borough':'DOBorough'}, inplace=True)\n",
    "\n",
    "\n",
    "#vemos los viajes para saber si esto funciono bien \n",
    "display(trips.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:48:27.130319Z",
     "start_time": "2021-01-23T16:48:26.917436Z"
    }
   },
   "outputs": [],
   "source": [
    "trips.drop(trips.index[np.where(trips['trip_duration_min'] <= 0)], inplace=True) #tiramos si la duracion de viajes es 0 o mneos \n",
    "display(len(trips[trips['trip_duration_min']>200])) #y tambien para ver tiramos si hay outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:48:28.677706Z",
     "start_time": "2021-01-23T16:48:28.659541Z"
    }
   },
   "outputs": [],
   "source": [
    "trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:48:31.973013Z",
     "start_time": "2021-01-23T16:48:30.731301Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# conjunto de todos los vecindarios \n",
    "Boroughs = list(set(zone_lookup['Borough']))\n",
    "Boroughs[Boroughs.index('Staten Island')] = 'StatenIsland'\n",
    "del Boroughs[Boroughs.index('Unknown')] \n",
    "#liberamos memorio\n",
    "Bronx = trips[(trips['PUBorough']==trips['DOBorough']) & (trips['PUBorough']=='Bronx')]['trip_duration_min']\n",
    "Brooklyn = trips[(trips['PUBorough']==trips['DOBorough']) & (trips['PUBorough']=='Brooklyn')]['trip_duration_min']\n",
    "EWR = trips[(trips['PUBorough']==trips['DOBorough']) & (trips['PUBorough']=='EWR')]['trip_duration_min']\n",
    "Manhattan = trips[(trips['PUBorough']==trips['DOBorough']) & (trips['PUBorough']=='Manhattan')]['trip_duration_min']\n",
    "Queens = trips[(trips['PUBorough']==trips['DOBorough']) & (trips['PUBorough']=='Queens')]['trip_duration_min']\n",
    "StatenIsland = trips[(trips['PUBorough']==trips['DOBorough']) & (trips['PUBorough']=='StatenIsland')]['trip_duration_min']\n",
    "SwitchedBorough = trips[trips['PUBorough']!=trips['DOBorough']]['trip_duration_min']\n",
    "#SwitchedBorough puede ser especificada o llamada como encontrar la los viajes más frecuentes entre 2 vecindario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:48:33.401599Z",
     "start_time": "2021-01-23T16:48:33.387066Z"
    }
   },
   "outputs": [],
   "source": [
    "SwitchedBorough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:48:38.767517Z",
     "start_time": "2021-01-23T16:48:37.600403Z"
    }
   },
   "outputs": [],
   "source": [
    "df31 = pd.DataFrame()\n",
    "for B in Boroughs:\n",
    "    df32 = eval(\"pd.DataFrame({'Duration':\" + B +\",'Borough':['\"+str(B)+\"']*len(\"+B+\")})\")\n",
    "    df31 = pd.concat([df31, df32])\n",
    "\n",
    "df31 = pd.concat([df31, pd.DataFrame({'Duration':SwitchedBorough,'Borough':['SwitchedBorough']*len(SwitchedBorough)})])\n",
    "\n",
    "    \n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "sns.boxenplot(x=\"Borough\", y=\"Duration\",\n",
    "              color=\"b\", order= Boroughs+['SwitchedBorough'],\n",
    "              scale=\"linear\", data=df31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviamente, se puede ver que hay algunos valores atípicos en los datos, especialmente para Manhattan, Bronx, Brooklyn y Queens. Generalmente, los valores atípicos están por encima de 500 minutos. Podemos ignorarlos ya que tenemos demasiados datos. También podemos observar la distribución de datos de manera más efectiva, y para esto ocuparemos una técnica estadístca llamada Z-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En estadística, la puntuación estándar es el número de desviaciones estándar por las que el valor de una puntuación bruta (es decir, un valor observado o un punto de datos) está por encima o por debajo del valor medio de lo que se está observando o midiendo. Los puntajes brutos por encima de la media tienen puntajes estándar positivos, mientras que los que están por debajo de la media tienen puntajes estándar negativos.\n",
    "\n",
    "Se calcula restando la media de la población de una puntuación bruta individual y luego dividiendo la diferencia por la desviación estándar de la población. Este proceso de convertir una puntuación bruta en una puntuación estándar se denomina estandarización o normalización (sin embargo, \"normalizar\" puede referirse a muchos tipos de proporciones; consulte normalización para obtener más información: https://en.wikipedia.org/wiki/Standard_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4.3.1 Verificación formal usando z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:48:41.961221Z",
     "start_time": "2021-01-23T16:48:41.797005Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "Bronx_z = np.abs(stat.zscore(Bronx))\n",
    "Bronx.drop(Bronx.index[np.where(Bronx_z > 3)], inplace=True) #np.where(Bronx_z > 3)\n",
    "Brooklyn_z = np.abs(stat.zscore(Brooklyn))\n",
    "Brooklyn.drop(Brooklyn.index[np.where(Brooklyn_z > 3)], inplace=True) \n",
    "\n",
    "EWR_z = np.abs(stat.zscore(EWR))\n",
    "EWR.drop(EWR.index[np.where(EWR_z > 3)], inplace=True)\n",
    "\n",
    "Manhattan_z = np.abs(stat.zscore(Manhattan))\n",
    "Manhattan.drop(Manhattan.index[np.where(Manhattan_z > 3)], inplace=True)\n",
    "\n",
    "Queens_z = np.abs(stat.zscore(Queens))\n",
    "Queens.drop(Queens.index[np.where(Queens_z > 3)], inplace=True)\n",
    "\n",
    "StatenIsland_z = np.abs(stat.zscore(StatenIsland))\n",
    "StatenIsland.drop(StatenIsland.index[np.where(StatenIsland_z > 3)], inplace=True)\n",
    "\n",
    "SwitchedBorough_z = np.abs(stat.zscore(SwitchedBorough))\n",
    "SwitchedBorough.drop(SwitchedBorough.index[np.where(SwitchedBorough_z > 3)], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:48:49.262039Z",
     "start_time": "2021-01-23T16:48:48.142409Z"
    }
   },
   "outputs": [],
   "source": [
    "df_wo_outliers = pd.DataFrame()\n",
    "for B in Boroughs:\n",
    "    df2 = eval(\"pd.DataFrame({'Duration':\" + B +\",'Borough':['\"+str(B)+\"']*len(\"+B+\")})\")\n",
    "    df_wo_outliers = pd.concat([df_wo_outliers, df2])\n",
    "df_wo_outliers = pd.concat([df_wo_outliers,\n",
    "                            pd.DataFrame({'Duration':SwitchedBorough,'Borough':['SwitchedBorough']*len(SwitchedBorough)})])\n",
    "\n",
    "#check visually again;\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "sns.boxenplot(x=\"Borough\", y=\"Duration\",\n",
    "              color=\"b\", order= Boroughs+['SwitchedBorough'],\n",
    "              scale=\"linear\", data=df_wo_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ahora está más claro. Según el diagrama de caja, Bronx tiene la mayor cantidad de valores atípicos. Al igual que Manhattan,  Queens solo tiene un valor atípico. La mediana de la duración del viaje es similar para Manhattan, Bronx, Brooklyn y Queens. Además, en Manhattan, la gente tiende a hacer más viajes cortos. Los datos de SwitchedBorough se difunden más porque, por lo general, lleva más tiempo viajar fuera de la ciudad. Por eso también tiene muchos valores atípicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Aproximación de la distribución empírica a la teoríca "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empíricamente intentaremos ajustar alguna distribución a nuestros datos para cada distrito. Entonces, encontrarán los mejores parámetros para la distribución especificada. Se utilizará la suma del error cuadrado (SSE) cuando se comparen las distribuciones entre sí. Por tanto, la distribución con SSE mínima será la que mejor se ajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T23:26:14.712268Z",
     "start_time": "2021-01-23T23:26:14.679325Z"
    }
   },
   "outputs": [],
   "source": [
    "#Encontramos la mejor distribucion que se le ajusta a los datos\n",
    "\n",
    "def bestDist(data, bins=200):\n",
    "    #Obtenemos el histograma de los dtaos originales \n",
    "    y, x = np.histogram(data,bins=bins, density=True)\n",
    "    x = (x + np.roll(x, -1))[:-1] / 2.0 # dado que hay 200 bins, los separamos por igual en el eje X\n",
    "                   \n",
    "    #En Scipy, existen muchas distribuciones pero aqui solo selecciono las que suelen modelar mejor estos eventos:\n",
    "    DISTRIBUTIONS = [ stat.beta,stat.cauchy,stat.chi2,stat.expon,stat.exponnorm,stat.gamma,stat.laplace,stat.logistic,\n",
    "                     stat.lognorm,stat.norm,stat.pareto,stat.rayleigh,stat.uniform ]\n",
    "    # La que mejor se ajusto ; solo para corroborar, le asignamos algunas muestras\n",
    "    best_distribution = stat.norm\n",
    "    best_params = (0.0, 1.0)\n",
    "    best_sse = np.inf\n",
    "        \n",
    "    #Probaremos todas las distribuciones de arriba para estimar los parametros de la distribucion de los datos originales\n",
    "    for dist in DISTRIBUTIONS:\n",
    "         # tratamos de hacer encajar la distribucion\n",
    "        try:\n",
    "            # Ignoramos la advertencia de los datos no pueden ser ajustados (\"outliers\")\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore')\n",
    "                # fit dist to data\n",
    "                prms = dist.fit(data)  #fit nos ayuda a encontrar los mejores parametros a la distribucion\n",
    "                #Separamos las partes de los parametros tales como, la localizacion, escala y kurtosis, si es que existen\n",
    "                arg = prms[:-2]\n",
    "                loc = prms[-2]\n",
    "                scale = prms[-1]\n",
    "        \n",
    "             #Después de haber encontrado los mejores parametros de la distribucion especificada, calcularemos la \n",
    "                #densidad ajustada y veremos la suma de errores al cuadrado\"\"\"\n",
    "                pdf = dist.pdf(x, loc=loc, scale=scale, *arg) #it generates pdf from x; remember that we generate x from our original data to fit the histogram\n",
    "                sse = np.sum(np.power(y - pdf, 2)) #sum of square error. this is our decision criteria\n",
    "                # Si se ajusto al modelo, que lo plotee\n",
    "                try:\n",
    "                    if ax:\n",
    "                        pd.Series(pdf, x).plot(ax=ax)\n",
    "                    end\n",
    "                except Exception:\n",
    "                    pass\n",
    "                # Si se encuentra un mejor párametro con menor error al cuadrado, que lo sustituya \n",
    "                if best_sse > sse > 0:\n",
    "                    best_dist = dist\n",
    "                    best_prms = prms\n",
    "                    best_sse = sse\n",
    "        \n",
    "        except Exception:\n",
    "            pass\n",
    "    return (best_dist.name, best_prms)\n",
    "\n",
    "#Guardemos la mejor distribucion y sus parametros y usemoslos para generar la pdf.\n",
    "    \n",
    "def pdf(best_dist, best_prms, size=1000):\n",
    "    # Separate parts of parameters\n",
    "    arg = best_prms[:-2]\n",
    "    loc = best_prms[-2]\n",
    "    scale = best_prms[-1]\n",
    "\n",
    "      #empecemos con la grafica \n",
    "    \"ppf se refiere a la funcion de distribucion inversa (tambien llamada de percentiles)\"\n",
    "\n",
    "    start = best_dist.ppf(0.001, *arg, loc=loc, scale=scale) if arg else best_dist.ppf(0.001, loc=loc, scale=scale)\n",
    "    end = best_dist.ppf(0.999, *arg, loc=loc, scale=scale) if arg else best_dist.ppf(0.999, loc=loc, scale=scale)\n",
    "\n",
    "    # Ahora creamos la pdf\n",
    "    x = np.linspace(start, end, size) #ya debemos de saber que np.linspace nos da un array que contiene numeros entre a,b de tamaño size\n",
    "    y = best_dist.pdf(x, loc=loc, scale=scale, *arg) \n",
    "    pdf = pd.Series(y, x)\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T01:28:57.079916Z",
     "start_time": "2020-12-29T01:28:57.070921Z"
    }
   },
   "source": [
    "Lo probamos para todos los distritos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 Queens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:49:01.228041Z",
     "start_time": "2021-01-23T16:48:58.888527Z"
    }
   },
   "outputs": [],
   "source": [
    "# Queens\n",
    "Qns_best_fit_name, Qns_best_fit_prms = bestDist(Queens, bins=200)\n",
    "Qns_best_dist = getattr(stat, Qns_best_fit_name) #getattr() nos regresa el valor del atributo nombrado del objeto\n",
    "\n",
    "Qns_pdf = pdf(Qns_best_dist, Qns_best_fit_prms)\n",
    "\n",
    "Qns_prm = list(map(lambda x: \"%.3f\" % x, Qns_best_fit_prms)) #for the title round the parameters\n",
    "\n",
    "#Creamos el histograma y le sobreponemos una pdf\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "Qns_pdf.plot(lw=2, label='pdf', legend=True, ax=ax)\n",
    "ax2 = ax.twinx()\n",
    "sns.distplot(Queens, bins=50,kde=False, color=\"g\", ax=ax2)\n",
    "\n",
    "plt.xlabel(u'Duración (min)')\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.title(u'El mejor ajuste de distribución para Queens\\n'+Qns_best_fit_name+' con parámetros \\n'  +'('+Qns_prm[0]+','+Qns_prm[1]+')') # \n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4 Brooklyn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T23:26:21.163704Z",
     "start_time": "2021-01-23T23:26:19.623032Z"
    }
   },
   "outputs": [],
   "source": [
    "# Brooklyn\n",
    "Bklyn_best_fit_name, Bklyn_best_fit_prms = bestDist(Brooklyn, bins=200)\n",
    "Bklyn_best_dist = getattr(stat, Bklyn_best_fit_name) #getattr() nos regresa el valor del atributo nombrado del objeto\n",
    "\n",
    "Bklyn_pdf = pdf(Bklyn_best_dist, Bklyn_best_fit_prms)\n",
    "\n",
    "Bklyn_prm = list(map(lambda x: \"%.3f\" % x, Bklyn_best_fit_prms)) #for the title round the parameters\n",
    "\n",
    "#Creamos el histograma y le sobreponemos una pdf\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "Bklyn_pdf.plot(lw=2, label='pdf', legend=True, ax=ax)\n",
    "ax2 = ax.twinx()\n",
    "sns.distplot(Brooklyn, bins=50,kde=False, color=\"g\", ax=ax2)\n",
    "\n",
    "plt.xlabel(u'Duración (min)')\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.title(u'El mejor ajuste de distribución para Brooklyn\\n'+Bklyn_best_fit_name+' con parámtros \\n' \n",
    "          +'('+Bklyn_prm[0]+','+Bklyn_prm[1]+','+Bklyn_prm[2]+')') # You can comment this line out if you don't need title\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dado que los datos de Brooklyn disminuyen repentinamente hasta los 15 minutos de duración del viaje, obtuvimos una distribución exponencialmente normal, también se denomina distribución gaussiana modificada exponencialmente (EMG). Podemos decir que Brooklyn está a punto de encajar con más datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos de EWR y Staten Island no son demasiados. Así que no es necesario estimar su distribución. Por ejemplo, EWR son 108 observaciones y 78 para Staten Island"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.5 Bronx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:49:18.941697Z",
     "start_time": "2021-01-23T16:49:18.360282Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bronx\n",
    "Brnx_best_fit_name, Brnx_best_fit_prms = bestDist(Bronx, bins=100)\n",
    "Brnx_best_dist = getattr(stat, Brnx_best_fit_name) #getattr() nos regresa el valor del atributo nombrado del objeto\n",
    "\n",
    "Brnx_pdf = pdf(Brnx_best_dist, Brnx_best_fit_prms)\n",
    "\n",
    "Brnx_prm = list(map(lambda x: \"%.3f\" % x, Brnx_best_fit_prms)) #for the title round the parameters\n",
    "\n",
    "#Creamos el histograma y le sobreponemos una pdf\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "Brnx_pdf.plot(lw=2, label='pdf', legend=True, ax=ax)\n",
    "ax2 = ax.twinx()\n",
    "sns.distplot(Bronx, bins=50,kde=False, color=\"g\", ax=ax2)\n",
    "\n",
    "plt.xlabel(u'Duración (min)')\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.title(u'El mejor ajuste de distribución para Bronx\\n'+Brnx_best_fit_name+' con parámetros \\n' \n",
    "          +'('+Brnx_prm[0]+','+Brnx_prm[1]+','+Brnx_prm[2]+')') # You can comment this line out if you don't need title\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El último es Cambios de Vecindario. Eso significa que examinaremos si el taxi va de un distrito a otro. Esperamos que la duración de los viajes sea larga todo el tiempo. Por lo tanto, lo más probable es que obtengamos una distribución de cola pesada como lognormal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.6 Cambios de Vecindario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:49:52.522731Z",
     "start_time": "2021-01-23T16:49:25.859816Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cambios de Vecindario\n",
    "SBoro_best_fit_name, SBoro_best_fit_prms = bestDist(SwitchedBorough, bins=200)\n",
    "SBoro_best_dist = getattr(stat, SBoro_best_fit_name) #getattr() nos regresa el valor del atributo nombrado del objeto \n",
    "\n",
    "SBoro_pdf = pdf(SBoro_best_dist, SBoro_best_fit_prms)\n",
    "\n",
    "SBoro_prm = list(map(lambda x: \"%.3f\" % x, Bklyn_best_fit_prms)) #Generamos el titulo con los parámetros expuestos \n",
    "\n",
    "#Creamos el histograma y le sobreponemos una pdf\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "SBoro_pdf.plot(lw=2, label='pdf', legend=True, ax=ax)\n",
    "ax2 = ax.twinx()\n",
    "sns.distplot(SwitchedBorough, bins=50,kde=False, color=\"g\", ax=ax2)\n",
    "\n",
    "plt.xlabel(u'Duración (min)')\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.title(u'EL mejor ajuste de distribución cuando el  viaje es entre dos distritos\\n'+SBoro_best_fit_name+' con parámetros \\n' \n",
    "          +'('+SBoro_prm[0]+','+SBoro_prm[1]+','+SBoro_prm[2]+')') # You can comment this line out if you don't need title\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.7 Manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:53:25.442083Z",
     "start_time": "2021-01-23T16:50:15.119145Z"
    }
   },
   "outputs": [],
   "source": [
    "# Manhattan;\n",
    "Man_best_fit_name, Man_best_fit_prms = bestDist(Manhattan, bins=200)\n",
    "Man_best_dist = getattr(stat, Man_best_fit_name) #getattr() nos regresa el valor del atributo nombrado del objeto\n",
    "Man_pdf = pdf(Man_best_dist, Man_best_fit_prms)\n",
    "Man_prm = list(map(lambda x: \"%.3f\" % x, Man_best_fit_prms)) #Generamos el titulo con los parámetros expuestos\n",
    "#Creamos el histograma y le sobreponemos una pdf\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "fig, ax = plt.subplots()\n",
    "Man_pdf.plot(lw=2, label='pdf', legend=True, ax=ax)\n",
    "ax2 = ax.twinx()\n",
    "sns.distplot(Manhattan, bins=50,kde=False, color=\"g\", ax=ax2)\n",
    "plt.xlabel(u'Duración (min)')\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.title(u'El mejor ajuste de distribución para Manhattan\\n'+Man_best_fit_name+' con parámetros \\n' \n",
    "          +'('+Man_prm[0]+','+Man_prm[1]+','+Man_prm[2]+')') # You can comment this line out if you don't need title\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones para RQ3\n",
    "Dado que los viajes se acumulan en algún momento, alrededor de 25 minutos, obtuvimos una distribución exponencialmente normal. Eso tiene sentido. Debido a que es fácil de adivinar si cambia de distrito, tomará más tiempo. Entonces no hay muchos datos para viajes cortos. Además, exponencialmente normal también se ajusta bien a los datos.\n",
    "\n",
    "Por lo tanto, generalmente obtuvimos una distribución sesgada correcta cuando el taxi está en el mismo municipio. Los datos están sesgados a la derecha porque, en general, la gente hace viajes cortos en Nueva York. Sin embargo, si cambia de municipio, debería acumularse. En promedio, toma media hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:53:38.462157Z",
     "start_time": "2021-01-23T16:53:38.446142Z"
    }
   },
   "outputs": [],
   "source": [
    "# No ejecutes esto hasta que acabes.\n",
    "del df3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4.- Tipos de Pago más frecuente "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál es la forma de pago más común? Descubramos la forma en que se ejecutan los pagos en cada municipio y visualizemos el número de pagos por cualquier medio posible. Luego, ejecutaremos la prueba Chi-cuadrado para ver si el método de pago está correlacionado con el municipio.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La única columna que necesitamos es 'payment_type' y, como es habitual, 'PULocationID' para unirse a los distritos.\n",
    "\n",
    "En lugar de usar la función 'del', asignamos el puntero de las variables temporales a una nueva lista, el recolector de basura hace el resto del trabajo.\n",
    "\n",
    "Para datos más comprensibles usamos un mapa (diccionario) que para cada PaymentID asocia el método de pago correspondiente, esto será útil porque podemos vectorizar la operación de convertir payment_type en una cadena más comprensible.\n",
    "\n",
    "El marco de datos resultante finalmente se compone de dos columnas: una contiene el método de pago del viaje como una cadena y la otra contiene el municipio en el que se realizó la recogida.\n",
    "\n",
    "Rellenamos los NA con 0 para que en el proceso de ingeniería de datos podamos simplemente omitirlos con un uso inteligente de los diccionarios de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:54:05.420604Z",
     "start_time": "2021-01-23T16:54:05.410646Z"
    }
   },
   "outputs": [],
   "source": [
    "number_to_payment = {1: \"Credit Card\",2: \"Cash\",3: \"No Charge\", 4: \"Dispute\",5: \"Unknown\",6: \"Voided Trip\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:54:07.478471Z",
     "start_time": "2021-01-23T16:54:07.091980Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df4 = df[['payment_type', 'LocationID']]\n",
    "# Recordemos que Zone_lookup (fue el csv que te pase) es lo que nos permite tener un mapeo entre LocationID y Borough (Borough)\n",
    "df4 = df4.merge(zone_lookup[['LocationID', 'Borough']], how='inner' ,on='LocationID').fillna(0) #Inner join between the interested columns and the previous dataset\n",
    "df4 = df4[['payment_type', 'Borough']]\n",
    "df4['payment_type'] = df4['payment_type'].map(number_to_payment)\n",
    "display(df4.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### -Ingeniería de datos:\n",
    "    Necesitamos construir un marco de datos que para cada municipio almacene el recuento de métodos de pago, por lo que usamos nuevamente funciones vectorizadas para acelerar las actuaciones. El resultado del siguiente fragmento es un marco de datos con los distritos en las filas y los métodos de pago en las columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:54:11.974135Z",
     "start_time": "2021-01-23T16:54:10.853313Z"
    }
   },
   "outputs": [],
   "source": [
    "#Aquí solo es para crear el dataframe vacío donde guardaremos los datos\n",
    "df42 = pd.DataFrame(columns=[el for el in set(df4['Borough'])],  index=[el for el in set(df4['payment_type'])])\n",
    "\n",
    "#for every borough\n",
    "for key in set(df4['Borough']):\n",
    "    #Agrupar registros en un dataframe vacío y contar, el cambio de nombre puede ser obsoleto pero por razones de seguridad podemos dejarlo aquí\n",
    "    df42[key] = df4.loc[df4['Borough'] == key].groupby('payment_type').count().rename(index=str, columns={'Borough':key})\n",
    "\n",
    "df42 = df42.T.fillna(0)\n",
    "display(df42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Gráfica \n",
    "    Es interesante trazar los resultados del marco de datos y su transposición para obtener más información sobre lo que está sucediendo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:54:24.994601Z",
     "start_time": "2021-01-23T16:54:24.597174Z"
    }
   },
   "outputs": [],
   "source": [
    "df42.plot(kind='bar')\n",
    "df42.T.plot(kind = 'bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:54:29.705341Z",
     "start_time": "2021-01-23T16:54:29.585420Z"
    }
   },
   "outputs": [],
   "source": [
    "df4[\"Borough\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:54:32.273029Z",
     "start_time": "2021-01-23T16:54:31.350455Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:54:36.353298Z",
     "start_time": "2021-01-23T16:54:36.206477Z"
    }
   },
   "outputs": [],
   "source": [
    "df1[\"Borough\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T02:18:48.978808Z",
     "start_time": "2020-12-29T02:18:48.959861Z"
    }
   },
   "source": [
    "###### $\\chi^2$ Test:\n",
    "       Usamos una función de construcción de la biblioteca scipy para calcular la prueba estadística definida de la siguente manera:\n",
    "<center> $\\chi^2 =\\sum_{i=1}^{n}\\frac{(O_i - E-_i)^2}{E_i}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:54:38.323687Z",
     "start_time": "2021-01-23T16:54:38.299667Z"
    }
   },
   "outputs": [],
   "source": [
    "stat.chi2_contingency(df42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo con la teoría de la prueba $ \\chi^2$, no se rechaza la hipótesis nula y la prueba dice que el método de pago está altamente correlacionado con el municipio.\n",
    "La forma más común de pagar un taxi en Nueva York es con la tarjeta de crédito, en segundo lugar está el efectivo.\n",
    "Hay tres distritos sin datos suficientes para ver en la trama lo que está sucediendo, y son: \"EWR,\" Staten Island \"y\" Bronx \"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:54:47.794179Z",
     "start_time": "2021-01-23T16:54:47.778160Z"
    }
   },
   "outputs": [],
   "source": [
    "del df4\n",
    "del df42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4.6 .- Correlación entre la distancia del viaje\n",
    "¿Se correlaciona una larga distancia con la duración del viaje en promedio? Haz una gráfica que muestre la dependencia entre la distancia y la duración del viaje. Luego calcule el coeficiente de Pearson, ¿es significativo? Comenta los resultados que obtengas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:38:02.160589Z",
     "start_time": "2021-01-22T20:38:02.140642Z"
    }
   },
   "outputs": [],
   "source": [
    "df5 = df[['tpep_pickup_datetime','tpep_dropoff_datetime','trip_distance', 'trip_duration_min']]\n",
    "display(df5.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpie aquellas filas que están incluidas en los valores cero de 'trip_distance', esto es para evitar valores atípicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:38:04.334204Z",
     "start_time": "2021-01-22T20:38:04.307276Z"
    }
   },
   "outputs": [],
   "source": [
    "df5=df5[(df5.trip_distance > 0) & (df5.trip_distance < 100) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:38:06.408790Z",
     "start_time": "2021-01-22T20:38:06.392802Z"
    }
   },
   "outputs": [],
   "source": [
    "df5['trip_duration_hou']= df5['trip_duration_min'] / 60 #df.apply(getRowDuration, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:38:16.591153Z",
     "start_time": "2021-01-22T20:38:11.758675Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(x = df5['trip_distance'], y = df5['trip_duration_hou'], c = df5['trip_distance'] + df5['trip_duration_hou'], alpha= 0.75)\n",
    "plt.xlabel(\"Trip Distance\")\n",
    "plt.ylabel(\"Duration\")\n",
    "plt.title(\"Scatter_Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:38:18.917261Z",
     "start_time": "2021-01-22T20:38:18.876411Z"
    }
   },
   "outputs": [],
   "source": [
    "corr, p_value = pearsonr(df5['trip_distance'], df5['trip_duration_hou'])\n",
    "print (\"The Pearson correlation coefficient calculated with scipy is: \" + str(\"%0.2f\"%corr))\n",
    "print (\"The Pearson correlation coefficient calculated with pandas is: \" + str(\"%0.2f\"%df5['trip_distance'].corr(df5['trip_duration_hou'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:39:00.444129Z",
     "start_time": "2021-01-22T20:39:00.428173Z"
    }
   },
   "outputs": [],
   "source": [
    "## CRQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:39:01.316003Z",
     "start_time": "2021-01-22T20:39:01.094560Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:39:05.070333Z",
     "start_time": "2021-01-22T20:39:05.003482Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Old size: %d' % len(df))\n",
    "df = df[df.trip_distance>0]\n",
    "print('New size: %d' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:39:05.717310Z",
     "start_time": "2021-01-22T20:39:05.682406Z"
    }
   },
   "outputs": [],
   "source": [
    "corr, p_value = pearsonr(df5['trip_distance'], df5['trip_duration_hou'])\n",
    "print (\"The Pearson correlation coefficient calculated with scipy is: \" + str(\"%0.2f\"%corr))\n",
    "print (\"The Pearson correlation coefficient calculated with pandas is: \" + str(\"%0.2f\"%df5['trip_distance'].corr(df5['trip_duration_hou'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6.- ¿La tarifa por milla cambia en el distrito de Nueva York? ¶ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   \n",
    "        ¿La tarifa por milla cambia en el distrito de Nueva York? Queremos descubrir si los gastos de un usuario que disfruta de Taxis en una zona es diferente a los que lo utiliza en otra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:40:47.926296Z",
     "start_time": "2021-01-22T20:40:47.707888Z"
    }
   },
   "outputs": [],
   "source": [
    "dfcrq1 = df[['trip_distance', 'fare_amount', 'LocationID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'trip_duration_min']].fillna(0)\n",
    "     \n",
    "#after the nested loop i have to perform some manipulations in order to have the complete the dataframe \n",
    "#zone_lookup = pd.read_csv(\"/Users/ince/Desktop/uni/adm/hws/hw2/taxi_zone_lookup.csv\") # this dataset have a map between the LocationID and Borough\n",
    "dfcrq1 = dfcrq1.merge(zone_lookup[['LocationID', 'Borough']], how='inner' ,on='LocationID').fillna(0) #Inner join between the interested columns and the previous dataset\n",
    "dfcrq1 = dfcrq1.loc[(dfcrq1['trip_distance'] > 0) & #removing the < 0 mile-distance records\n",
    "                    (dfcrq1['fare_amount'] > 0) & \n",
    "                    (dfcrq1['tpep_pickup_datetime'].dt.year == 2018) &\n",
    "                    (dfcrq1['tpep_dropoff_datetime'].dt.year == 2018) &\n",
    "                    (dfcrq1['trip_distance'] < 100)].reset_index() #removing the > 100 mile-distance records\n",
    "\n",
    "dfcrq1 = dfcrq1.drop(['LocationID', 'index'], axis=1) #drop useless columns\n",
    "\n",
    "dfcrq1['$/mile'] = dfcrq1['fare_amount'] / dfcrq1['trip_distance'] #calc the dollar per mile amount\n",
    "dfcrq1['$*minutes/mile'] = dfcrq1['$/mile']*dfcrq1['trip_duration_min']\n",
    "display(dfcrq1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:40:50.569357Z",
     "start_time": "2021-01-22T20:40:50.551369Z"
    }
   },
   "outputs": [],
   "source": [
    "new_york_dollar_per_mile_mean = dfcrq1['$/mile'].mean()\n",
    "new_york_dollar_per_mile_std = dfcrq1['$/mile'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:42:26.570892Z",
     "start_time": "2021-01-22T20:42:25.755829Z"
    }
   },
   "outputs": [],
   "source": [
    "labels, values = zip(*Counter(dfcrq1['$/mile'].round(decimals=1)).items())\n",
    "\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1.7\n",
    "plt.xlim(0,400)\n",
    "\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xlabel('$/mile')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in the distribution there's some outlier, in the next section we want to evaluate if they're really outliers or maybe some traffic issues. Also the distribution is not Gaussian so in theory we cannot run the t-test on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:42:36.345962Z",
     "start_time": "2021-01-22T20:42:36.197363Z"
    }
   },
   "outputs": [],
   "source": [
    "mean = dfcrq1.groupby('Borough').mean()['$/mile'] #this groups by borough, calc the mean and takes only the column that i want to plot\n",
    "std = dfcrq1.groupby('Borough').std()['$/mile'] #same as above, but for the standard deviaton\n",
    "dfcrq12 = pd.DataFrame([mean, std], columns=[el for el in set(dfcrq1['Borough'])],  index=['mean', 'std']) #combine the previous result in a dataframe\n",
    "dfcrq12['NY'] = pd.Series([new_york_dollar_per_mile_mean, new_york_dollar_per_mile_std], index = ['mean', 'std'])\n",
    "display(dfcrq12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:42:40.478498Z",
     "start_time": "2021-01-22T20:42:40.109452Z"
    }
   },
   "outputs": [],
   "source": [
    "dfcrq12.plot(kind='bar')\n",
    "dfcrq12.T.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:42:43.593451Z",
     "start_time": "2021-01-22T20:42:43.570539Z"
    }
   },
   "outputs": [],
   "source": [
    "dfcrq1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:42:47.699890Z",
     "start_time": "2021-01-22T20:42:46.793287Z"
    }
   },
   "outputs": [],
   "source": [
    "dfcrq13 = pd.DataFrame()\n",
    "combs = list(it.combinations(set(dfcrq1['Borough']), 2))\n",
    "for b1,b2 in combs:\n",
    "    ttest_result = stat.ttest_ind(dfcrq1.loc[dfcrq1['Borough'] == b1]['$/mile'], dfcrq1.loc[dfcrq1['Borough'] == b2]['$/mile'])\n",
    "    dfcrq13[b1+'-'+b2] = pd.Series([ttest_result[0], ttest_result[1]], index=['ttest', 'pval'])\n",
    "display(dfcrq13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:42:52.195049Z",
     "start_time": "2021-01-22T20:42:51.634278Z"
    }
   },
   "outputs": [],
   "source": [
    "x = range(len(set(dfcrq13)))\n",
    "x_labels = set(dfcrq13)\n",
    "y = [dfcrq13[i][0] for i in x_labels]\n",
    "\n",
    "markerline, stemlines, baseline = plt.stem(x,y, '-.')\n",
    "plt.setp(baseline, color='orchid', linewidth=1)\n",
    "plt.title('TTest')\n",
    "plt.xticks(x, x_labels, rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "y = [dfcrq13[i][1] for i in x_labels]\n",
    "\n",
    "markerline, stemlines, baseline = plt.stem(x,y, '-.')\n",
    "plt.setp(baseline, color='orchid', linewidth=1)\n",
    "plt.title('p-val')\n",
    "plt.xticks(x, x_labels, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8.- Visualización geográfica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    ¡Visualicemos los movimientos de los taxis! NYC está dividida en muchas zonas de taxis. Para cada viaje en taxi amarillo conocemos la zona en la que el Taxi recoge y deja a los usuarios. Visualicemos, en un mapa de chropleth, el número de viajes que comienzan en cada zona. Luego, haz otro mapa para contar las carreras que terminan en la zona única."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:54:59.550355Z",
     "start_time": "2021-01-23T16:54:59.308317Z"
    }
   },
   "outputs": [],
   "source": [
    "dfcrq2 = df[['LocationID', 'DOLocationID']]\n",
    "geo_data = json.load(open(r'C:/Users/berri/Desktop/Arcade/nyu-2451-36743-geojson.json'))                          \n",
    "display(dfcrq2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:55:02.780419Z",
     "start_time": "2021-01-23T16:55:02.748408Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "NY=folium.Map(\n",
    "    location=[40.7142700, -74.0059700],   #coordinates of new York\n",
    "    zoom_start=11,                        \n",
    "    tiles='CartoDB positron'              #style of our map\n",
    ")\n",
    "NY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:55:07.616528Z",
     "start_time": "2021-01-23T16:55:07.086839Z"
    }
   },
   "outputs": [],
   "source": [
    "folium.GeoJson(geo_data,style_function=lambda feature: {'fillColor':'blue','color' : 'orchid','weight' : 1,'fillOpacity' : 0.5, 'colorOpacity' : 0.5 }).add_to(NY)\n",
    "NY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T00:28:51.311350Z",
     "start_time": "2021-01-12T00:28:50.815905Z"
    }
   },
   "outputs": [],
   "source": [
    "NY.save(outfile= \"test.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:43:23.747733Z",
     "start_time": "2021-01-22T20:43:23.539183Z"
    }
   },
   "outputs": [],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:55:15.606556Z",
     "start_time": "2021-01-23T16:55:15.502623Z"
    }
   },
   "outputs": [],
   "source": [
    "location_id_to_number_of_pickups=dfcrq2.groupby('LocationID')['LocationID'].count()\n",
    "location_id_to_number_of_dropoff=dfcrq2.groupby('DOLocationID')['DOLocationID'].count()\n",
    "\n",
    "location_id_to_number_of_pickups.head()\n",
    "\n",
    "df_zone_to_pickup_to_dropoff=pd.DataFrame(index=list(range(1,266)),columns=[])\n",
    "df_zone_to_pickup_to_dropoff['ZoneID']=list(range(1,266))\n",
    "\n",
    "zone_index_to_dropoff_number = []\n",
    "zone_index_to_pickup_number = []\n",
    "\n",
    "for i in range(1,266):\n",
    "    if i in location_id_to_number_of_pickups:\n",
    "        zone_index_to_pickup_number.append(location_id_to_number_of_pickups[i])\n",
    "    else:\n",
    "        zone_index_to_pickup_number.append(0)    \n",
    "        \n",
    "    if i in location_id_to_number_of_dropoff:\n",
    "        zone_index_to_dropoff_number.append(location_id_to_number_of_dropoff[i])\n",
    "    else:\n",
    "        zone_index_to_dropoff_number.append(0)     #Necesitamos esto para verificar que no haya 0 (puede haber 0 taxis en la zona)\n",
    "\n",
    "df_zone_to_pickup_to_dropoff['taxi_pickup'] = zone_index_to_pickup_number\n",
    "df_zone_to_pickup_to_dropoff['taxi_dropoff'] = zone_index_to_dropoff_number\n",
    "display(df_zone_to_pickup_to_dropoff.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:55:18.072515Z",
     "start_time": "2021-01-23T16:55:17.952555Z"
    }
   },
   "outputs": [],
   "source": [
    "from folium import plugins\n",
    "from folium.plugins import HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T00:02:00.633109Z",
     "start_time": "2021-01-24T00:01:59.987413Z"
    }
   },
   "outputs": [],
   "source": [
    "NY2 = folium.Map(\n",
    "    location=[40.7142700, -74.0059700],   #coordinates of new York\n",
    "    zoom_start=11,                        \n",
    "    tiles='CartoDB positron'              #style of our map\n",
    ")\n",
    "\n",
    "NY2.choropleth(\n",
    "    geo_data=geo_data,  #our geojson datas\n",
    "    data=df_zone_to_pickup_to_dropoff,    #our dataframe\n",
    "    columns=['ZoneID', \"taxi_pickup\"],\n",
    "    key_on='feature.properties.objectid', #the key in geojson file that way want to take as zone\n",
    "    fill_color='YlGnBu',   #the color scale that we want\n",
    "    fill_opacity=0.8,\n",
    "    line_opacity=0.2,\n",
    "    legend_name='Tipos de pago en el 2018',\n",
    "    highlight=True    #enable the highlight function, to enable highlight functionality when you hover over each area.\n",
    ")\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.7730135746, -73.8702298524],\n",
    "    popup='Airport LaGuardia',\n",
    "    icon=folium.Icon(icon='plane')\n",
    ").add_to(NY2)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.6413111, -73.7781391],\n",
    "    popup='John F. Kennedy International Airport',\n",
    "    icon=folium.Icon(icon='plane')\n",
    ").add_to(NY2)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.7828647, -73.9653551],\n",
    "    popup = 'Central Park',\n",
    "    icon=folium.Icon(color='red')\n",
    ").add_to(NY2)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.758895, -73.985131],\n",
    "    popup = 'Times Square',\n",
    "    icon=folium.Icon(color='red')\n",
    ").add_to(NY2)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.7061927, -74.0091604],\n",
    "    popup = 'Wall Street',\n",
    "    icon=folium.Icon(color='red')\n",
    ").add_to(NY2)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.692013, -74.181557],\n",
    "    popup='Newark Liberty International Airport',\n",
    "    icon=folium.Icon(icon='plane')\n",
    ").add_to(NY2)\n",
    "\n",
    "NY2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:55:35.772040Z",
     "start_time": "2021-01-23T16:55:35.211504Z"
    }
   },
   "outputs": [],
   "source": [
    "NY2 = folium.Map(\n",
    "    location=[40.7142700, -74.0059700],   #coordinates of new York\n",
    "    zoom_start=11,                        \n",
    "    tiles='CartoDB positron'              #style of our map\n",
    ")\n",
    "\n",
    "NY2.choropleth(\n",
    "    geo_data=geo_data,  #our geojson datas\n",
    "    data=df_zone_to_pickup_to_dropoff,    #our dataframe\n",
    "    columns=['ZoneID', 'taxi_dropoff'],\n",
    "    key_on='feature.properties.objectid', #the key in geojson file that way want to take as zone\n",
    "    fill_color='YlGnBu',   #the color scale that we want\n",
    "    fill_opacity=0.8,\n",
    "    line_opacity=0.2,\n",
    "    legend_name='Number of taxi taken in 2018',\n",
    "    highlight=True    #enable the highlight function, to enable highlight functionality when you hover over each area.\n",
    ")\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.7730135746, -73.8702298524],\n",
    "    popup='Airport LaGuardia',\n",
    "    icon=folium.Icon(icon='plane')\n",
    ").add_to(NY2)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.6413111, -73.7781391],\n",
    "    popup='John F. Kennedy International Airport',\n",
    "    icon=folium.Icon(icon='plane')\n",
    ").add_to(NY2)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.7828647, -73.9653551],\n",
    "    popup = 'Central Park',\n",
    "    icon=folium.Icon(color='red')\n",
    ").add_to(NY2)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.758895, -73.985131],\n",
    "    popup = 'Times Square',\n",
    "    icon=folium.Icon(color='red')\n",
    ").add_to(NY2)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.7061927, -74.0091604],\n",
    "    popup = 'Wall Street',\n",
    "    icon=folium.Icon(color='red')\n",
    ").add_to(NY2)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.692013, -74.181557],\n",
    "    popup='Newark Liberty International Airport',\n",
    "    icon=folium.Icon(icon='plane')\n",
    ").add_to(NY2)\n",
    "\n",
    "NY2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:55:46.660324Z",
     "start_time": "2021-01-23T16:55:46.101685Z"
    }
   },
   "outputs": [],
   "source": [
    "NY3 = folium.Map(\n",
    "    location=[40.7142700, -74.0059700],   #coordinates of new York\n",
    "    zoom_start=11,                        \n",
    "    tiles='CartoDB positron'              #style of our map\n",
    ")\n",
    "\n",
    "NY3.choropleth(\n",
    "    geo_data=geo_data,\n",
    "    data=df_zone_to_pickup_to_dropoff,\n",
    "    columns=['ZoneID', 'taxi_dropoff'],\n",
    "    key_on='feature.properties.objectid',\n",
    "    fill_color='YlGnBu',\n",
    "    fill_opacity=0.8,\n",
    "    line_opacity=0.2,\n",
    "    legend_name='Number of taxi drops in 2018',\n",
    "    highlight=True    \n",
    ")\n",
    "folium.Marker(\n",
    "    location=[40.7730135746, -73.8702298524],\n",
    "    popup='LaGuardia Airport',\n",
    "    icon=folium.Icon(icon='plane')\n",
    ").add_to(NY3)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.6413111, -73.7781391],\n",
    "    popup='John F. Kennedy International Airport',\n",
    "    icon=folium.Icon(icon='plane')\n",
    ").add_to(NY3)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.7828647, -73.9653551],\n",
    "    popup = 'Central Park',\n",
    "    icon=folium.Icon(color='red')\n",
    ").add_to(NY3)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.758895, -73.985131],\n",
    "    popup = 'Times Square',\n",
    "    icon=folium.Icon(color='red')\n",
    ").add_to(NY3)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.7061927, -74.0091604],\n",
    "    popup = 'Wall Street',\n",
    "    icon=folium.Icon(color='red')\n",
    ").add_to(NY3)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.692013, -74.181557],\n",
    "    popup='Newark Liberty International Airport',\n",
    "    icon=folium.Icon(icon='plane')\n",
    ").add_to(NY3)\n",
    "\n",
    "NY3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T00:08:43.254379Z",
     "start_time": "2020-12-28T00:08:43.246379Z"
    }
   },
   "outputs": [],
   "source": [
    "## En que Vecindarios se paga con que tipo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:55:57.847248Z",
     "start_time": "2021-01-23T16:55:57.735290Z"
    }
   },
   "outputs": [],
   "source": [
    "dfcrq3 = df[['payment_type', 'LocationID']]\n",
    "dfcrq3[dfcrq3.duplicated(subset=['LocationID'],keep=False)]\n",
    "dfcrq3.payment_type.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:56:00.125415Z",
     "start_time": "2021-01-23T16:55:59.889964Z"
    }
   },
   "outputs": [],
   "source": [
    "z = dfcrq3.groupby([\"LocationID\"])['payment_type'].apply(lambda x: x.mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:56:02.035030Z",
     "start_time": "2021-01-23T16:56:02.025113Z"
    }
   },
   "outputs": [],
   "source": [
    "z = z.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:56:04.040531Z",
     "start_time": "2021-01-23T16:56:04.030012Z"
    }
   },
   "outputs": [],
   "source": [
    "z['LocationID'] = z.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:56:06.019698Z",
     "start_time": "2021-01-23T16:56:06.003708Z"
    }
   },
   "outputs": [],
   "source": [
    "z[\"payment_type\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:56:11.353449Z",
     "start_time": "2021-01-23T16:56:11.337427Z"
    }
   },
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:56:16.277825Z",
     "start_time": "2021-01-23T16:56:15.732475Z"
    }
   },
   "outputs": [],
   "source": [
    "NY4 = folium.Map(\n",
    "    location=[40.7142700, -74.0059700],   #coordinates of new York\n",
    "    zoom_start=11,                        \n",
    "    tiles='CartoDB positron'              #style of our map\n",
    ")\n",
    "\n",
    "NY4.choropleth(\n",
    "    geo_data=geo_data,  #our geojson datas\n",
    "    data=z,    #our dataframe\n",
    "    columns=['LocationID', \"payment_type\"],\n",
    "    key_on='feature.properties.objectid', #the key in geojson file that way want to take as zone\n",
    "    fill_color='YlGnBu',   #the color scale that we want\n",
    "    fill_opacity=0.8,\n",
    "    line_opacity=0.2,\n",
    "    legend_name='Tipos de pago en el 2018',\n",
    "    highlight=True    #enable the highlight function, to enable highlight functionality when you hover over each area.\n",
    ")\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.7730135746, -73.8702298524],\n",
    "    popup='Airport LaGuardia',\n",
    "    icon=folium.Icon(icon='plane')\n",
    ").add_to(NY2)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.6413111, -73.7781391],\n",
    "    popup='John F. Kennedy International Airport',\n",
    "    icon=folium.Icon(icon='plane')\n",
    ").add_to(NY2)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.7828647, -73.9653551],\n",
    "    popup = 'Central Park',\n",
    "    icon=folium.Icon(color='red')\n",
    ").add_to(NY2)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.758895, -73.985131],\n",
    "    popup = 'Times Square',\n",
    "    icon=folium.Icon(color='red')\n",
    ").add_to(NY2)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.7061927, -74.0091604],\n",
    "    popup = 'Wall Street',\n",
    "    icon=folium.Icon(color='red')\n",
    ").add_to(NY2)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[40.692013, -74.181557],\n",
    "    popup='Newark Liberty International Airport',\n",
    "    icon=folium.Icon(icon='plane')\n",
    ").add_to(NY2)\n",
    "\n",
    "NY4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:46:39.432336Z",
     "start_time": "2021-01-22T20:46:38.951473Z"
    }
   },
   "outputs": [],
   "source": [
    "NY4.save(outfile= \"test.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:46:52.684930Z",
     "start_time": "2021-01-22T20:46:52.191440Z"
    }
   },
   "outputs": [],
   "source": [
    "NY3.save(outfile= \"test1.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:46:59.459288Z",
     "start_time": "2021-01-22T20:46:58.955886Z"
    }
   },
   "outputs": [],
   "source": [
    "NY2.save(outfile= \"test2.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T23:52:25.447605Z",
     "start_time": "2020-12-28T23:52:25.149106Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.- Regresión múltiple: $$\\mathbf{Y} = \\mathbb{X} \\underline{\\beta} + {\\varepsilon}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.- Creación de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1.- Indicio de dependencia lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:56:27.538339Z",
     "start_time": "2021-01-23T16:56:25.062643Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x='trip_distance',y='total_amount',data=df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.- Creación de columna \"mes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:56:48.999745Z",
     "start_time": "2021-01-23T16:56:48.755538Z"
    }
   },
   "outputs": [],
   "source": [
    "df['pickup_month']=df['tpep_pickup_datetime'].dt.month\n",
    "df['dropoff_month']=df['tpep_dropoff_datetime'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:56:51.322981Z",
     "start_time": "2021-01-23T16:56:51.100843Z"
    }
   },
   "outputs": [],
   "source": [
    "data2=df.loc[:,['passenger_count','total_amount','trip_duration_min', 'pickup_day', 'dropoff_day', 'pickup_month',\n",
    "   'dropoff_month','pickup_timezone','dropoff_timezone','trip_distance',\"store_and_fwd_flag\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:57:19.543588Z",
     "start_time": "2021-01-23T16:57:17.000257Z"
    }
   },
   "outputs": [],
   "source": [
    "df['log_distance']=np.log(df.trip_distance)\n",
    "df['log_fare_amount']=np.log(df.fare_amount)\n",
    "sns.scatterplot(x='log_distance',y='log_fare_amount',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2.- Elección de Variables que conformaran la matriz $\\mathbb{X}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:57:23.579053Z",
     "start_time": "2021-01-23T16:57:23.294696Z"
    }
   },
   "outputs": [],
   "source": [
    "data2=df.loc[:,['passenger_count','total_amount','trip_duration_min', 'pickup_day', 'dropoff_day', 'pickup_month',\n",
    "   'dropoff_month','pickup_timezone','dropoff_timezone','log_distance','trip_distance',\"store_and_fwd_flag\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 Creación de Variables Categorícas (Dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:57:27.011440Z",
     "start_time": "2021-01-23T16:57:25.968384Z"
    }
   },
   "outputs": [],
   "source": [
    "data2=pd.get_dummies(data2,columns=['pickup_day',\"passenger_count\",'dropoff_day','pickup_month','dropoff_month','pickup_timezone', 'dropoff_timezone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:57:31.250833Z",
     "start_time": "2021-01-23T16:57:30.979088Z"
    }
   },
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.4.- Matriz de Correlación "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T22:45:38.806746Z",
     "start_time": "2021-01-22T22:45:36.062012Z"
    }
   },
   "outputs": [],
   "source": [
    "data2.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T22:45:43.080412Z",
     "start_time": "2021-01-22T22:45:39.215643Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(data2.corr());\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.4 .- Creación de matriz $\\mathbb{X}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:57:43.403347Z",
     "start_time": "2021-01-23T16:57:43.395310Z"
    }
   },
   "outputs": [],
   "source": [
    "data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:57:47.335465Z",
     "start_time": "2021-01-23T16:57:47.319445Z"
    }
   },
   "outputs": [],
   "source": [
    "base_line_col=['trip_distance']\n",
    "predictor_cols=['passenger_count_1',\"passenger_count_2\",'trip_distance',\n",
    "               'pickup_day_Friday','pickup_day_Monday','pickup_day_Saturday','pickup_day_Sunday',\n",
    "               'pickup_day_Thursday','pickup_day_Tuesday','pickup_day_Wednesday','dropoff_day_Friday',\n",
    "               'dropoff_day_Monday','dropoff_day_Saturday','dropoff_day_Sunday','dropoff_day_Thursday',\n",
    "               'dropoff_day_Tuesday','dropoff_day_Wednesday','pickup_month_1','pickup_month_5','pickup_month_6',\n",
    "               'dropoff_month_1','dropoff_month_5','dropoff_month_6','pickup_timezone_Noche',\n",
    "               'pickup_timezone_Medio día','pickup_timezone_Mañana','dropoff_timezone_Atardecer',\n",
    "               'dropoff_timezone_Noche','dropoff_timezone_Medio día','dropoff_timezone_Mañana',\"trip_duration_min\"]\n",
    "target_col=['total_amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Importación del modelo desde sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:57:49.631251Z",
     "start_time": "2021-01-23T16:57:49.613103Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import  metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def modelfit(estimator,data_train,data_test,predictors,target):\n",
    "    #print(data_train.head())\n",
    "    #fitting model\n",
    "    estimator.fit(data_train[predictors],data_train.loc[:,target])\n",
    "    score = estimator.score(data_train[predictors],data_train.loc[:,target])\n",
    "    \n",
    "    #train data prediction\n",
    "    train_pred=estimator.predict(data_train[predictors])\n",
    "    #cross_validation score\n",
    "    cv_score=cross_val_score(estimator,data_train[predictors],data_train.loc[:,target],cv=20,scoring='neg_mean_squared_error')\n",
    "    \n",
    "    cv_score=np.sqrt(np.abs(cv_score))\n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"RMSE on Train Data: %.4g\" % np.sqrt(metrics.mean_squared_error(data_train.loc[:,target].values, train_pred)))\n",
    "    print (\"CV Score : Mean - %.4g | Std - %.4g | Min - %.4g | Max - %.4g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "    \n",
    "    test_pred=estimator.predict(data_test[predictors])\n",
    "    print (\"RMSE on Test Data: %.4g\" % np.sqrt(metrics.mean_squared_error(data_test.loc[:,target].values, test_pred)))\n",
    "    \n",
    "    print(score)\n",
    "    \n",
    "    \n",
    "    return test_pred, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Configuración de datos de entramiento y de validación "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:57:53.121414Z",
     "start_time": "2021-01-23T16:57:52.140194Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "validation_size = 0.70\n",
    "\n",
    "X_train, X_test = train_test_split(data2,test_size=validation_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:57:55.607863Z",
     "start_time": "2021-01-23T16:57:55.597870Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:57:58.123132Z",
     "start_time": "2021-01-23T16:57:58.033584Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_pred=np.repeat(X_train[target_col].mean(),len(X_test[target_col]))\n",
    "from sklearn.metrics import mean_squared_error as mae\n",
    "sqrt(mae(X_test[target_col],mean_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:58:01.817858Z",
     "start_time": "2021-01-23T16:58:00.718053Z"
    }
   },
   "outputs": [],
   "source": [
    "alg1 = LinearRegression(normalize=True)\n",
    "print('The baseline model')\n",
    "y_pred=modelfit(alg1, X_train, X_test,base_line_col,target_col)\n",
    "coef1 = alg1.coef_\n",
    "print('The coeffient is {}'.format(coef1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:58:19.881315Z",
     "start_time": "2021-01-23T16:58:04.969548Z"
    }
   },
   "outputs": [],
   "source": [
    "alg2 = LinearRegression(normalize=True)\n",
    "y_pred=modelfit(alg2, X_train, X_test, predictor_cols,target_col)\n",
    "coef1 = pd.Series(alg2.coef_[0], predictor_cols).sort_values()\n",
    "coef1.plot(kind='bar', title='Model Coefficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:58:37.256969Z",
     "start_time": "2021-01-23T16:58:36.327454Z"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels as sms\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:58:39.750757Z",
     "start_time": "2021-01-23T16:58:39.740656Z"
    }
   },
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:58:42.841251Z",
     "start_time": "2021-01-23T16:58:42.189790Z"
    }
   },
   "outputs": [],
   "source": [
    "regr.fit(X_train[predictor_cols], X_train.loc[:,target_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T16:58:45.298180Z",
     "start_time": "2021-01-23T16:58:45.290174Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print('Intercept: \\n', regr.intercept_)\n",
    "print('Coefficients: \\n', regr.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X_train[predictor_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T17:00:46.704956Z",
     "start_time": "2021-01-23T17:00:45.013432Z"
    }
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(X_train.loc[:,target_col],X_train[predictor_cols]).fit() \n",
    "predictions = model.predict(X_train[predictor_cols]) \n",
    " \n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T17:01:04.495101Z",
     "start_time": "2021-01-23T17:01:04.463120Z"
    }
   },
   "outputs": [],
   "source": [
    "model.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T17:01:09.803302Z",
     "start_time": "2021-01-23T17:01:09.539474Z"
    }
   },
   "outputs": [],
   "source": [
    "model.resid.hist(bins=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T17:01:14.803878Z",
     "start_time": "2021-01-23T17:01:14.787857Z"
    }
   },
   "outputs": [],
   "source": [
    "print('mean=%.3f stdv=%.3f' % (np.mean(model.resid), np.std(model.resid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T17:01:24.687959Z",
     "start_time": "2021-01-23T17:01:24.562773Z"
    }
   },
   "outputs": [],
   "source": [
    "from fitter import get_distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T17:01:30.618480Z",
     "start_time": "2021-01-23T17:01:30.561259Z"
    }
   },
   "outputs": [],
   "source": [
    "from fitter import Fitter\n",
    "f = Fitter(model.resid,distributions=['norm'])\n",
    "f.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T17:01:34.334878Z",
     "start_time": "2021-01-23T17:01:33.998991Z"
    }
   },
   "outputs": [],
   "source": [
    "f.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T00:14:58.949090Z",
     "start_time": "2021-01-23T00:14:58.741171Z"
    }
   },
   "outputs": [],
   "source": [
    "f.fitted_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T17:01:43.050289Z",
     "start_time": "2021-01-23T17:01:43.042293Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T17:01:45.851661Z",
     "start_time": "2021-01-23T17:01:45.795701Z"
    }
   },
   "outputs": [],
   "source": [
    "stat, p = shapiro(model.resid_pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T17:01:50.029166Z",
     "start_time": "2021-01-23T17:01:50.021170Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('La muestra se ve Gaussiana ( No Rechazamos H0)')\n",
    "else:\n",
    "\tprint('La muestra no se ve Gaussiana (Rechazamos H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T17:02:09.090597Z",
     "start_time": "2021-01-23T17:02:09.076920Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import anderson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T17:02:11.947390Z",
     "start_time": "2021-01-23T17:02:11.781092Z"
    }
   },
   "outputs": [],
   "source": [
    "result = anderson(model.resid_pearson)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T17:02:14.565608Z",
     "start_time": "2021-01-23T17:02:14.556044Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Statistic: %.3f' % result.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T17:02:17.648905Z",
     "start_time": "2021-01-23T17:02:17.640935Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(result.critical_values)):\n",
    "\tsl, cv = result.significance_level[i], result.critical_values[i]\n",
    "\tif result.statistic < result.critical_values[i]:\n",
    "\t\tprint('%.3f: %.3f, data looks normal (fail to reject H0)' % (sl, cv))\n",
    "\telse:\n",
    "\t\tprint('%.3f: %.3f, data does not look normal (reject H0)' % (sl, cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T00:32:00.399843Z",
     "start_time": "2021-01-23T00:31:59.622072Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "k2, p = stats.normaltest(model.resid_pearson)\n",
    "alpha = 0.05\n",
    "print(\"p = {:g}\".format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T00:32:02.488267Z",
     "start_time": "2021-01-23T00:32:02.293581Z"
    }
   },
   "outputs": [],
   "source": [
    "if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T00:31:47.070543Z",
     "start_time": "2021-01-23T00:31:46.683397Z"
    }
   },
   "outputs": [],
   "source": [
    "model.resid_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T00:41:43.965473Z",
     "start_time": "2021-01-23T00:41:21.930878Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    ">>> fig = sm.qqplot(model.resid, stats.t, distargs=(4,))\n",
    ">>> plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T00:47:56.298703Z",
     "start_time": "2021-01-23T00:47:29.445324Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = sm.qqplot(model.resid, stats.norm, fit=True, line=\"45\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T00:47:00.785870Z",
     "start_time": "2021-01-23T00:46:36.487772Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    ">>> fig = sm.qqplot(model.resid, stats.norm, loc=0, scale=1)\n",
    ">>> plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T00:50:40.057815Z",
     "start_time": "2021-01-23T00:50:39.945861Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T00:51:07.760976Z",
     "start_time": "2021-01-23T00:50:41.943991Z"
    }
   },
   "outputs": [],
   "source": [
    "qqplot(model.resid, line='s')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T22:46:27.756681Z",
     "start_time": "2021-01-22T22:46:27.740660Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T22:46:28.807851Z",
     "start_time": "2021-01-22T22:46:28.799832Z"
    }
   },
   "outputs": [],
   "source": [
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T22:46:30.114549Z",
     "start_time": "2021-01-22T22:46:30.106554Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train[\"total_amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T22:46:30.706388Z",
     "start_time": "2021-01-22T22:46:30.690357Z"
    }
   },
   "outputs": [],
   "source": [
    "validation = pd.concat([X_train[\"total_amount\"], predictions],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T22:46:31.850789Z",
     "start_time": "2021-01-22T22:46:31.827010Z"
    }
   },
   "outputs": [],
   "source": [
    "validation.reset_index=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T22:46:32.662014Z",
     "start_time": "2021-01-22T22:46:32.646003Z"
    }
   },
   "outputs": [],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T03:02:20.812143Z",
     "start_time": "2021-01-23T03:02:20.273519Z"
    }
   },
   "outputs": [],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T22:46:38.687722Z",
     "start_time": "2021-01-22T22:46:38.615770Z"
    }
   },
   "outputs": [],
   "source": [
    "#model = sm.OLS(X_test.loc[:,target_col],X_test[predictor_cols]).fit() \n",
    "predictions = model.predict(X_test[predictor_cols]) \n",
    " \n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T22:46:52.090578Z",
     "start_time": "2021-01-22T22:46:52.082583Z"
    }
   },
   "outputs": [],
   "source": [
    "(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T22:46:52.706205Z",
     "start_time": "2021-01-22T22:46:52.690214Z"
    }
   },
   "outputs": [],
   "source": [
    "(X_test[\"total_amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T22:47:00.837793Z",
     "start_time": "2021-01-22T22:47:00.821767Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fittedvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T22:47:01.687822Z",
     "start_time": "2021-01-22T22:47:01.679826Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test[\"total_amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T22:47:04.245312Z",
     "start_time": "2021-01-22T22:47:04.221289Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T22:47:13.047697Z",
     "start_time": "2021-01-22T22:47:13.039700Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fittedvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T20:42:08.348222Z",
     "start_time": "2021-01-23T20:42:02.119814Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6), dpi=120, facecolor='w', edgecolor='b')\n",
    "f = range(0,len(model.resid))\n",
    "k = [0 for i in range(0,len(model.resid))]\n",
    "plt.scatter( f, model.resid, label = 'residuals')\n",
    "plt.plot( f, k , color = 'red', label = 'regression line' )\n",
    "plt.xlabel('fitted points ')\n",
    "plt.ylabel('residuals')\n",
    "plt.title('Residual plot')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
